{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import pathlib\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shapely.geometry\n",
    "import skimage.draw\n",
    "import skimage.filters\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pydicom\n",
    "\n",
    "import pymedphys\n",
    "import pymedphys._dicom.structure as dcm_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it so any changes in pymedphys is automatically\n",
    "# propagated into the notebook without needing a kernel reset.\n",
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymedphys.labs.autosegmentation import indexing, softdice, filtering, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('name_mappings.json') as f:\n",
    "    name_mappings_config = json.load(f)\n",
    "    names_map = name_mappings_config[\"names_map\"]\n",
    "    ignore_list = name_mappings_config[\"ignore_list\"]\n",
    "    \n",
    "    for key in ignore_list:\n",
    "        names_map[key] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to verify that all structures have either been ignored or mapped to a name\n",
    "\n",
    "# names = set()\n",
    "\n",
    "# for uid, path in structure_set_paths.items():\n",
    "#     dcm = pydicom.read_file(\n",
    "#         path, force=True, specific_tags=['StructureSetROISequence'])\n",
    "#     for item in dcm.StructureSetROISequence:\n",
    "#         names.add(item.ROIName)\n",
    "\n",
    "# mapped_names = set(names_map.keys())\n",
    "# print(mapped_names.difference(names))\n",
    "# names.difference(mapped_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_list_of_structures = list(set([item for key, item in names_map.items()]).difference({None}))\n",
    "# full_list_of_structures = sorted(full_list_of_structures)\n",
    "# full_list_of_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all of the SASH DICOM data within a directory called 'dicom' in here:\n",
    "data_path_root = pathlib.Path.home().joinpath('.data/dicom-ct-and-structures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_image_paths, structure_set_paths, ct_uid_to_structure_uid, structure_uid_to_ct_uids = indexing.get_uid_cache(data_path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_names_by_ct_uid, structure_names_by_structure_set_uid = indexing.get_cached_structure_names_by_uids(\n",
    "    data_path_root, structure_set_paths, names_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for the following structures, in the following order\n",
    "structures_to_learn = [\n",
    "    'lens_left', 'lens_right', 'eye_left', 'eye_right', 'patient']\n",
    "\n",
    "# Only use a study set if all of the following are defined on that study set\n",
    "study_set_must_have_all_of = structures_to_learn\n",
    "\n",
    "# Only use a slice if one of the following contours exists on it\n",
    "slice_at_least_one_of = [\n",
    "    'lens_left', 'lens_right', 'eye_left', 'eye_right']\n",
    "slice_must_have = ['patient']\n",
    "slice_cannot_have = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ct_uids = filtering.filter_ct_uids(\n",
    "    structure_uid_to_ct_uids,\n",
    "    structure_names_by_structure_set_uid,\n",
    "    structure_names_by_ct_uid,\n",
    "    study_set_must_have_all_of,\n",
    "    slice_at_least_one_of,\n",
    "    slice_must_have,\n",
    "    slice_cannot_have,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct_uids_to_train_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len({1, 2,3, 4}.intersection({2,3,5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(filtered_ct_uids)\n",
    "\n",
    "dataset = pipeline.create_numpy_generator_dataset(\n",
    "    data_path_root,\n",
    "    structure_set_paths,\n",
    "    ct_image_paths,\n",
    "    ct_uid_to_structure_uid,\n",
    "    names_map,\n",
    "    filtered_ct_uids,\n",
    "    structures_to_learn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ct_uid, x_grid, y_grid, input_array, output_array in dataset.take(1):\n",
    "    print(ct_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialised_dataset = from_numpy_dataset.map(tf_serialise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialised_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = str(tfrecord_directory.joinpath(\n",
    "    'lense-eye-patient.tfrecord'))\n",
    "# writer = tf.data.experimental.TFRecordWriter(tfrecord_path)\n",
    "# writer.write(serialised_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "for ct_uid, input_array, output_array in from_numpy_dataset.take(100):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_features = {\n",
    "    'ct_uid': tf.io.FixedLenFeature([], tf.string),\n",
    "    'input_array': tf.io.FixedLenFeature([], tf.string),\n",
    "    'output_array': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_dataset(example_proto):\n",
    "    parsed = tf.io.parse_single_example(example_proto, parse_features)\n",
    "    ct_uid = tf.io.parse_tensor(parsed['ct_uid'], tf.string)\n",
    "    input_array = tf.io.parse_tensor(parsed['input_array'], tf.int32)\n",
    "    output_array = tf.io.parse_tensor(parsed['output_array'], tf.float64)\n",
    "\n",
    "    return ct_uid, input_array, output_array\n",
    "    \n",
    "\n",
    "parsed_dataset = raw_dataset.map(_parse_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "for ct_uid, input_array, output_array in parsed_dataset.take(100):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
